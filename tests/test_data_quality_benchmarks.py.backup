# SPDX-License-Identifier: MIT
# Copyright (c) 2024 MusicScope

"""
Tests for data quality benchmarking functionality.

These tests verify performance measurement capabilities including
scan speed, memory usage, and accuracy metrics.
"""

import time
from unittest.mock import Mock, patch

import pytest
from sqlalchemy import create_engine, text

from data_quality.benchmarks import (
    BenchmarkResult,
    benchmark_scan_speed,
    benchmark_memory_usage,
    benchmark_accuracy,
    run_comprehensive_benchmarks,
)


def create_test_database(database_url: str, num_rows: int = 1000):
    """
    Create a test database with sample data for benchmarking.

    Args:
        database_url: Database connection URL
        num_rows: Number of rows to create in test tables
    """
    engine = create_engine(database_url)

    with engine.connect() as conn:
        # Create test tables
        conn.execute(text("""
            CREATE TABLE IF NOT EXISTS songs (
                id INTEGER PRIMARY KEY,
                title TEXT NOT NULL,
                artist TEXT,
                duration INTEGER,
                release_year INTEGER
            )
        """))
        conn.execute(text("""
            CREATE TABLE IF NOT EXISTS albums (
                id INTEGER PRIMARY KEY,
                name TEXT NOT NULL,
                artist TEXT,
                release_year INTEGER
            )
        """))
        conn.commit()

        # Insert test data
        for i in range(num_rows):
            conn.execute(text("""
                INSERT INTO songs (id, title, artist, duration, release_year)
                VALUES (:id, :title, :artist, :duration, :year)
            """), {
                "id": i + 1,
                "title": f"Song {i + 1}",
                "artist": f"Artist {(i % 100) + 1}" if i % 10 != 0 else None,  # Some nulls
                "duration": 180 + (i % 300),
                "year": 2000 + (i % 24)
            })

        # Insert album data (fewer rows)
        for i in range(num_rows // 10):
            conn.execute(text("""
                INSERT INTO albums (id, name, artist, release_year)
                VALUES (:id, :name, :artist, :year)
            """), {
                "id": i + 1,
                "name": f"Album {i + 1}",
                "artist": f"Artist {(i % 50) + 1}",
                "year": 2000 + (i % 24)
            })

        conn.commit()

    engine.dispose()
    return database_url


class TestBenchmarkResult:
    """Test BenchmarkResult dataclass."""

    def test_benchmark_result_creation(self):
        """Test creating a BenchmarkResult."""
        result = BenchmarkResult(
            test_name="scan_speed",
            rows_processed=1000000,
            time_seconds=2.5,
            memory_mb=150.0,
            rows_per_second=400000,
            accuracy_score=0.95,
            metadata={"database": "test", "table_count": 5}
        )

        assert result.test_name == "scan_speed"
        assert result.rows_processed == 1000000
        assert result.time_seconds == 2.5
        assert result.memory_mb == 150.0
        assert result.rows_per_second == 400000
        assert result.accuracy_score == 0.95
        assert result.metadata["database"] == "test"


class TestScanSpeedBenchmark:
    """Test scan speed benchmarking."""

    def test_benchmark_scan_speed_small_dataset(self):
        """Test scan speed benchmark with small dataset."""
        db_url = "sqlite+pysqlite:///:memory:"
        create_test_database(db_url, 1000)
        result = benchmark_scan_speed(db_url)

        assert result.test_name == "scan_speed"
        assert result.rows_processed >= 1000  # At least 1000 rows
        assert result.time_seconds > 0
        assert result.rows_per_second > 0
        assert 0 <= result.accuracy_score <= 1.0
        assert "database_type" in result.metadata

    def test_benchmark_scan_speed_large_dataset(self):
        """Test scan speed benchmark with large dataset."""
        db_url = "sqlite+pysqlite:///:memory:"
        create_test_database(db_url, 10000)
        result = benchmark_scan_speed(db_url)

        assert result.test_name == "scan_speed"
        assert result.rows_processed >= 10000  # At least 10000 rows
        assert result.time_seconds > 0
        assert result.rows_per_second > 0

    def test_benchmark_scan_speed_calculates_rows_per_second(self):
        """Test that scan speed benchmark calculates rows per second correctly."""
        db_url = "sqlite+pysqlite:///:memory:"
        create_test_database(db_url, 5000)
        result = benchmark_scan_speed(db_url)

        # Verify calculation: rows_per_second = rows_processed / time_seconds
        expected_rps = int(result.rows_processed / result.time_seconds)
        assert abs(result.rows_per_second - expected_rps) <= 1  # Allow for rounding


class TestMemoryUsageBenchmark:
    """Test memory usage benchmarking."""

    def test_benchmark_memory_usage_tracks_peak(self):
        """Test that memory benchmark tracks peak usage."""
        db_url = "sqlite+pysqlite:///:memory:"
        create_test_database(db_url, 3000)
        result = benchmark_memory_usage(db_url, 3)

        assert result.test_name == "memory_usage"
        assert result.memory_mb >= 0
        assert "peak_memory_mb" in result.metadata
        assert result.metadata["peak_memory_mb"] >= result.metadata["initial_memory_mb"]

    def test_benchmark_memory_usage_large_scan(self):
        """Test memory usage during large database scan."""
        db_url = "sqlite+pysqlite:///:memory:"
        create_test_database(db_url, 5000)
        result = benchmark_memory_usage(db_url, 5)

        assert result.test_name == "memory_usage"
        assert result.memory_mb >= 0
        assert result.metadata["table_count"] >= 1  # At least one table


class TestAccuracyBenchmark:
    """Test accuracy benchmarking."""

    def test_benchmark_accuracy_known_dataset(self):
        """Test accuracy benchmark with known issues."""
        db_url = "sqlite+pysqlite:///:memory:"
        create_test_database(db_url, 2000)
        result = benchmark_accuracy(db_url, 20)

        assert result.test_name == "accuracy"
        assert 0 <= result.accuracy_score <= 1.0
        assert result.metadata["known_issues"] == 20
        assert "detected_issues" in result.metadata

    def test_benchmark_accuracy_perfect_dataset(self):
        """Test accuracy benchmark with perfect dataset."""
        db_url = "sqlite+pysqlite:///:memory:"
        create_test_database(db_url, 1000)
        result = benchmark_accuracy(db_url, 0)  # No known issues

        assert result.test_name == "accuracy"
        assert result.accuracy_score >= 0.0
        assert result.metadata["known_issues"] == 0


class TestComprehensiveBenchmarks:
    """Test comprehensive benchmark suite."""

    def test_run_comprehensive_benchmarks(self):
        """Test running all benchmarks together."""
        db_url = "sqlite+pysqlite:///:memory:"
        create_test_database(db_url, 2000)
        results = run_comprehensive_benchmarks(db_url)

        assert len(results) == 3  # scan_speed, memory_usage, accuracy
        test_names = {r.test_name for r in results}
        assert test_names == {"scan_speed", "memory_usage", "accuracy"}

    def test_comprehensive_benchmarks_returns_results(self):
        """Test that comprehensive benchmarks return structured results."""
        db_url = "sqlite+pysqlite:///:memory:"
        create_test_database(db_url, 2000)
        results = run_comprehensive_benchmarks(db_url)

        assert len(results) == 3
        for result in results:
            assert isinstance(result, BenchmarkResult)
            assert result.rows_processed > 0
            assert result.time_seconds > 0


class TestBenchmarkRequirements:
    """Test specific benchmark requirements from the spec."""

    def test_scan_speed_per_million_rows(self):
        """Test measuring scan speed per million rows."""
        # Requirement: measuring scan speed per million rows
        from data_quality.benchmarks import benchmark_scan_speed

        # Test with small dataset for speed
        db_url = "sqlite:///:memory:"
        create_test_database(db_url, 1000)
        result = benchmark_scan_speed(db_url)

        assert result.test_name == "scan_speed"
        assert result.rows_processed >= 1000
        assert result.time_seconds > 0
        assert result.rows_per_second > 0
        assert 0 <= result.accuracy_score <= 1.0

    def test_memory_usage_during_large_scans(self):
        """Test measuring memory usage during large scans."""
        # Requirement: memory usage during large scans
        from data_quality.benchmarks import benchmark_memory_usage

        # Test with small dataset for speed
        db_url = "sqlite:///:memory:"
        create_test_database(db_url, 3000)
        result = benchmark_memory_usage(db_url, 3)

        assert result.test_name == "memory_usage"
        assert result.rows_processed > 0
        assert result.time_seconds > 0
        assert result.memory_mb >= 0  # Memory usage can be 0 in test environments

    def test_accuracy_metrics(self):
        """Test measuring accuracy metrics."""
        # Requirement: accuracy metrics
        from data_quality.benchmarks import benchmark_accuracy

        # Test with small dataset for speed
        db_url = "sqlite:///:memory:"
        create_test_database(db_url, 1000)
        result = benchmark_accuracy(db_url, 10)

        assert result.test_name == "accuracy"
        assert result.rows_processed > 0
        assert result.time_seconds > 0
        assert 0 <= result.accuracy_score <= 1.0
        assert "known_issues" in result.metadata
        assert "detected_issues" in result.metadata


class TestBenchmarkIntegration:
    """Integration tests for benchmarking with real scenarios."""

    def test_benchmark_with_sqlite_database(self):
        """Test benchmarking with SQLite database."""
        from data_quality.benchmarks import run_comprehensive_benchmarks

        # Mock the comprehensive benchmarks to run faster
        import unittest.mock
        with unittest.mock.patch('data_quality.benchmarks.benchmark_scan_speed') as mock_speed, \
             unittest.mock.patch('data_quality.benchmarks.benchmark_memory_usage') as mock_memory, \
             unittest.mock.patch('data_quality.benchmarks.benchmark_accuracy') as mock_accuracy:

            # Mock return values
            from data_quality.benchmarks import BenchmarkResult
            mock_speed.return_value = BenchmarkResult("scan_speed", 1000, 0.1, 5.0, 10000, 0.9, {})
            mock_memory.return_value = BenchmarkResult("memory_usage", 1000, 0.1, 10.0, 10000, 0.8, {})
            mock_accuracy.return_value = BenchmarkResult("accuracy", 1000, 0.1, 2.0, 10000, 0.95, {})

            results = run_comprehensive_benchmarks("sqlite:///:memory:")

            assert len(results) == 3
            assert all(isinstance(r, BenchmarkResult) for r in results)

    def test_benchmark_performance_regression(self):
        """Test that benchmarks can detect performance regressions."""
        from data_quality.benchmarks import benchmark_scan_speed

        # Run two benchmarks and compare (simplified test)
        db_url1 = "sqlite:///:memory:"
        create_test_database(db_url1, 100)
        result1 = benchmark_scan_speed(db_url1)

        db_url2 = "sqlite:///:memory:"
        create_test_database(db_url2, 100)
        result2 = benchmark_scan_speed(db_url2)

        # Both should complete successfully
        assert result1.rows_per_second > 0
        assert result2.rows_per_second > 0

        # Performance should be reasonably consistent (within 10x factor)
        ratio = max(result1.rows_per_second, result2.rows_per_second) / min(result1.rows_per_second, result2.rows_per_second)
        assert ratio < 10.0  # Performance shouldn't vary by more than 10x
